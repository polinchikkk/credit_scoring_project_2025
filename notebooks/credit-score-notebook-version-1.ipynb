{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11545199,"sourceType":"datasetVersion","datasetId":7240174},{"sourceId":11588867,"sourceType":"datasetVersion","datasetId":7240513}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport pandas as pd\nimport torch\nimport sys\nimport torch.nn as nn\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score\nimport pickle\nimport numpy as np\nimport tqdm\nsys.path.append('/kaggle/input/utilit')\nfrom utils                      import read_parquet_dataset_from_local \nfrom dataset_preprocessing_utils import features, transform_credits_to_sequences, pad_sequence, create_padded_buckets\nfrom data_generators            import batches_generator","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-27T15:48:19.908288Z","iopub.execute_input":"2025-04-27T15:48:19.908654Z","iopub.status.idle":"2025-04-27T15:48:28.943009Z","shell.execute_reply.started":"2025-04-27T15:48:19.908622Z","shell.execute_reply":"2025-04-27T15:48:28.942437Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# задаем пути файлов (ручная загрузка)\nTRAIN_DATA_PATH = \"/kaggle/input/data-for-credit-score/data_for_competition/train_data\"\nTEST_DATA_PATH = \"/kaggle/input/data-for-credit-score/data_for_competition/test_data\"\nTRAIN_TARGET_PATH = \"/kaggle/input/data-for-credit-score/data_for_competition/train_target.csv\"\nTEST_TARGET_PATH = \"/kaggle/input/data-for-credit-score/data_for_competition/test_target.csv\"\n\n# задаем пути для предобработанных данных\nTRAIN_BUCKETS_PATH = \"/kaggle/working/train_buckets_rnn\"\nVAL_BUCKETS_PATH = \"/kaggle/working/val_buckets_rnn\"\nTEST_BUCKETS_PATH = \"/kaggle/working/test_buckets_rnn\"\nfor p in [TRAIN_BUCKETS_PATH, VAL_BUCKETS_PATH, TEST_BUCKETS_PATH]:\n    os.makedirs(p, exist_ok=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T15:48:32.189267Z","iopub.execute_input":"2025-04-27T15:48:32.190038Z","iopub.status.idle":"2025-04-27T15:48:32.195233Z","shell.execute_reply.started":"2025-04-27T15:48:32.190005Z","shell.execute_reply":"2025-04-27T15:48:32.194452Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"bucket_info = dict(zip(range(1, 59),\n                       list(range(1, 41)) + [45]*5 + [50]*5 + [58]*8))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T15:48:35.199851Z","iopub.execute_input":"2025-04-27T15:48:35.200116Z","iopub.status.idle":"2025-04-27T15:48:35.204417Z","shell.execute_reply.started":"2025-04-27T15:48:35.200098Z","shell.execute_reply":"2025-04-27T15:48:35.203762Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"train_target_df = pd.read_csv(TRAIN_TARGET_PATH)\ntrain_ids, val_ids = train_test_split(train_target_df,\n                                      test_size=0.10,\n                                      random_state=42)\nprint(f\"Train id: {len(train_ids)}, Val id: {len(val_ids)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T15:48:36.776531Z","iopub.execute_input":"2025-04-27T15:48:36.776822Z","iopub.status.idle":"2025-04-27T15:48:37.674930Z","shell.execute_reply.started":"2025-04-27T15:48:36.776801Z","shell.execute_reply":"2025-04-27T15:48:37.674145Z"}},"outputs":[{"name":"stdout","text":"Train id: 2700000, Val id: 300000\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"def create_buckets_from_credits(path_to_dataset, bucket_info, save_to_path, frame_with_ids=None,\n                                num_parts_to_preprocess_at_once: int = 1,\n                                num_parts_total=50, has_target=False):\n    block = 0\n    for step in tqdm.notebook.tqdm(range(0, num_parts_total, num_parts_to_preprocess_at_once),\n                     desc=\"Preparing credit data\"):\n        credits_frame = read_parquet_dataset_from_local(path_to_dataset, step, num_parts_to_preprocess_at_once, verbose=True)\n        credits_frame.loc[:, features] += 1  \n        seq = transform_credits_to_sequences(credits_frame)  \n\n        print(\"Transforming credits to sequences is done.\")\n        \n        if frame_with_ids is not None:\n            seq = seq.merge(frame_with_ids, on=\"id\")\n\n        block_as_str = str(block).zfill(3) \n        file_name = os.path.join(save_to_path, f\"processed_chunk_{block_as_str}.pkl\")\n        \n        processed_fragment = create_padded_buckets(seq, bucket_info=bucket_info, has_target=has_target, \n                                                   save_to_file_path=file_name)\n        block += 1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T15:48:39.005906Z","iopub.execute_input":"2025-04-27T15:48:39.006210Z","iopub.status.idle":"2025-04-27T15:48:39.012673Z","shell.execute_reply.started":"2025-04-27T15:48:39.006185Z","shell.execute_reply":"2025-04-27T15:48:39.011956Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"create_buckets_from_credits(TRAIN_DATA_PATH, bucket_info,\n                            TRAIN_BUCKETS_PATH, frame_with_ids=train_ids,\n                            num_parts_to_preprocess_at_once=4, num_parts_total=12, has_target=True)\n\ncreate_buckets_from_credits(TRAIN_DATA_PATH, bucket_info,\n                            VAL_BUCKETS_PATH, frame_with_ids=val_ids,\n                            num_parts_to_preprocess_at_once=4, num_parts_total=12, has_target=True)\n\ncreate_buckets_from_credits(TEST_DATA_PATH, bucket_info,\n                            TEST_BUCKETS_PATH, frame_with_ids=None,\n                            num_parts_to_preprocess_at_once=2, num_parts_total=2, has_target=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T15:48:41.677164Z","iopub.execute_input":"2025-04-27T15:48:41.677749Z","iopub.status.idle":"2025-04-27T16:08:01.496713Z","shell.execute_reply.started":"2025-04-27T15:48:41.677726Z","shell.execute_reply":"2025-04-27T16:08:01.495794Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Preparing credit data:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1747f9b6043f4cf3ac744120d25b002c"}},"metadata":{}},{"name":"stdout","text":"Reading chunks:\n/kaggle/input/data-for-credit-score/data_for_competition/train_data/train_data_0.pq\n/kaggle/input/data-for-credit-score/data_for_competition/train_data/train_data_1.pq\n/kaggle/input/data-for-credit-score/data_for_competition/train_data/train_data_2.pq\n/kaggle/input/data-for-credit-score/data_for_competition/train_data/train_data_3.pq\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Reading dataset with pandas:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c55b270238024c8e809c9041b339d83c"}},"metadata":{}},{"name":"stdout","text":"Transforming credits to sequences is done.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Extracting buckets:   0%|          | 0/43 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f1fb6a9798514abea9c09a3fa3baab95"}},"metadata":{}},{"name":"stdout","text":"Reading chunks:\n/kaggle/input/data-for-credit-score/data_for_competition/train_data/train_data_4.pq\n/kaggle/input/data-for-credit-score/data_for_competition/train_data/train_data_5.pq\n/kaggle/input/data-for-credit-score/data_for_competition/train_data/train_data_6.pq\n/kaggle/input/data-for-credit-score/data_for_competition/train_data/train_data_7.pq\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Reading dataset with pandas:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"98f91c8e26644730878fb79abf881fa7"}},"metadata":{}},{"name":"stdout","text":"Transforming credits to sequences is done.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Extracting buckets:   0%|          | 0/43 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"716f42c26e594b7cae0dc60ab94af798"}},"metadata":{}},{"name":"stdout","text":"Reading chunks:\n/kaggle/input/data-for-credit-score/data_for_competition/train_data/train_data_8.pq\n/kaggle/input/data-for-credit-score/data_for_competition/train_data/train_data_9.pq\n/kaggle/input/data-for-credit-score/data_for_competition/train_data/train_data_10.pq\n/kaggle/input/data-for-credit-score/data_for_competition/train_data/train_data_11.pq\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Reading dataset with pandas:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cf9b365df467444f917bf1dec3d2cec0"}},"metadata":{}},{"name":"stdout","text":"Transforming credits to sequences is done.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Extracting buckets:   0%|          | 0/42 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e55f18d294e2494d8634521246422da9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Preparing credit data:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2f6cd41047704be3bd8dd972c1ac3092"}},"metadata":{}},{"name":"stdout","text":"Reading chunks:\n/kaggle/input/data-for-credit-score/data_for_competition/train_data/train_data_0.pq\n/kaggle/input/data-for-credit-score/data_for_competition/train_data/train_data_1.pq\n/kaggle/input/data-for-credit-score/data_for_competition/train_data/train_data_2.pq\n/kaggle/input/data-for-credit-score/data_for_competition/train_data/train_data_3.pq\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Reading dataset with pandas:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2665e246642944379fdba3c217875b8f"}},"metadata":{}},{"name":"stdout","text":"Transforming credits to sequences is done.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Extracting buckets:   0%|          | 0/41 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2fd7a0b374d1480597733059655c2a02"}},"metadata":{}},{"name":"stdout","text":"Reading chunks:\n/kaggle/input/data-for-credit-score/data_for_competition/train_data/train_data_4.pq\n/kaggle/input/data-for-credit-score/data_for_competition/train_data/train_data_5.pq\n/kaggle/input/data-for-credit-score/data_for_competition/train_data/train_data_6.pq\n/kaggle/input/data-for-credit-score/data_for_competition/train_data/train_data_7.pq\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Reading dataset with pandas:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d3dd5dce0ad445778189046134da90df"}},"metadata":{}},{"name":"stdout","text":"Transforming credits to sequences is done.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Extracting buckets:   0%|          | 0/41 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2b8e8e63e7b8452da52e59dbeca0fbf8"}},"metadata":{}},{"name":"stdout","text":"Reading chunks:\n/kaggle/input/data-for-credit-score/data_for_competition/train_data/train_data_8.pq\n/kaggle/input/data-for-credit-score/data_for_competition/train_data/train_data_9.pq\n/kaggle/input/data-for-credit-score/data_for_competition/train_data/train_data_10.pq\n/kaggle/input/data-for-credit-score/data_for_competition/train_data/train_data_11.pq\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Reading dataset with pandas:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"75ff5b76d43c4193930d923876a42985"}},"metadata":{}},{"name":"stdout","text":"Transforming credits to sequences is done.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Extracting buckets:   0%|          | 0/43 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4e53caa3449c499a9d0260f6b37b3fb3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Preparing credit data:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aa6b7249ef8843c1bd077c48386acb6e"}},"metadata":{}},{"name":"stdout","text":"Reading chunks:\n/kaggle/input/data-for-credit-score/data_for_competition/test_data/test_data_0.pq\n/kaggle/input/data-for-credit-score/data_for_competition/test_data/test_data_1.pq\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Reading dataset with pandas:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"966839684e66466d91f47178f2020dd8"}},"metadata":{}},{"name":"stdout","text":"Transforming credits to sequences is done.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Extracting buckets:   0%|          | 0/43 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"32bd9798fc174660bff0b67d9b734ab4"}},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"class EarlyStopping:\n    def __init__(self, patience=7, mode='min', verbose=False, delta=0, save_path='checkpoint.hdf5', metric_name=None, save_format='torch'):\n        if mode not in [\"min\", \"max\"]:\n            raise ValueError(f\"Unrecognized mode: {mode}! Please choose one of the following modes: \\\"min\\\", \\\"max\\\"\")\n\n        if save_format not in [\"torch\", \"tf\"]:\n            raise ValueError(f\"Unrecognized format: {save_format}! Please choose one of the following formats: \\\"torch\\\", \\\"tf\\\"\")\n\n        self.patience = patience\n        self.mode = mode\n        self.verbose = verbose\n        self.counter = 0\n        self.best_score = None\n        self.early_stop = False\n        self.best_prev_score = np.Inf if mode == \"min\" else -np.Inf\n        self.delta = delta\n        self.save_path = save_path\n        self.metric_name = \"metric\" if not metric_name else metric_name\n        self.save_format = save_format\n\n    def __call__(self, metric_value, model):\n\n        score = -metric_value if self.mode == \"min\" else metric_value\n\n        if self.best_score is None:\n            self.best_score = score\n            self.save_checkpoint(metric_value, model)\n        elif score < self.best_score + self.delta:\n            self.counter += 1\n            print(\n                f\"No imporvement in validation {self.metric_name}. Current: {score:.6f}. Current best: {self.best_score:.6f}\")\n            print(f\"EarlyStopping counter: {self.counter} out of {self.patience}\")\n            if self.counter >= self.patience:\n                self.early_stop = True\n        else:\n            self.best_score = score\n            self.save_checkpoint(metric_value, model)\n            self.counter = 0\n\n    def save_checkpoint(self, metric_value: float, model: torch.nn.Module or tensorflow.keras.Model):\n        if self.verbose:\n            print(\n                f\"Validation {self.metric_name} improved ({self.best_prev_score:.6f} --> {metric_value:.6f}).  Saving model...\")\n        if self.save_format == \"tf\":\n            model.save_weights(self.save_path)\n        else:\n            torch.save(model.state_dict(), self.save_path)\n\n        self.best_prev_score = metric_value","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T16:10:13.692495Z","iopub.execute_input":"2025-04-27T16:10:13.693260Z","iopub.status.idle":"2025-04-27T16:10:13.705334Z","shell.execute_reply.started":"2025-04-27T16:10:13.693233Z","shell.execute_reply":"2025-04-27T16:10:13.704636Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"train_paths = sorted([os.path.join(TRAIN_BUCKETS_PATH, f) for f in os.listdir(TRAIN_BUCKETS_PATH)])\nval_paths   = sorted([os.path.join(VAL_BUCKETS_PATH,   f) for f in os.listdir(VAL_BUCKETS_PATH)])\ntest_paths  = sorted([os.path.join(TEST_BUCKETS_PATH,  f) for f in os.listdir(TEST_BUCKETS_PATH)])\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\ntrain_gen = batches_generator(train_paths, batch_size=128, shuffle=True,\n                              is_train=True,  output_format=\"torch\", device=device)\nval_gen   = batches_generator(val_paths,   batch_size=128, shuffle=False,\n                              is_train=True,  output_format=\"torch\", device=device)\ntest_gen  = batches_generator(test_paths,  batch_size=128, shuffle=False,\n                              is_train=False, output_format=\"torch\", device=device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T16:10:17.074891Z","iopub.execute_input":"2025-04-27T16:10:17.075387Z","iopub.status.idle":"2025-04-27T16:10:17.537301Z","shell.execute_reply.started":"2025-04-27T16:10:17.075362Z","shell.execute_reply":"2025-04-27T16:10:17.536761Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"def compute_embed_dim(n_cat):        \n    return min(600, round(1.6 * (n_cat ** 0.56)))\n\ncard = {f: 0 for f in features}\nfor start in range(0, 12, 4):\n    part = read_parquet_dataset_from_local(TRAIN_DATA_PATH, start, 4, columns=features)\n    for f in features:\n        card[f] = max(card[f], part[f].max()+1)    # +1 после сдвига\n    del part\nembed_proj = {f: (card[f]+1, compute_embed_dim(card[f]+1)) for f in features}\n\nclass CreditsRNN(nn.Module):\n    def __init__(self, features, embedding_proj, rnn_units=128, mlp_units=32):\n        super().__init__()\n        self.embeddings = nn.ModuleList([nn.Embedding(num, dim, padding_idx=0)\n                                         for num, dim in embedding_proj.values()])\n        self.rnn = nn.GRU(sum(dim for _, dim in embedding_proj.values()),\n                          rnn_units, batch_first=True)\n        self.head = nn.Sequential(\n            nn.Linear(rnn_units, mlp_units),\n            nn.ReLU(),\n            nn.Linear(mlp_units, 1)\n        )\n    def forward(self, feats):                         \n        x = torch.cat([emb(feats[i]) for i, emb in enumerate(self.embeddings)], dim=-1)\n        _, h = self.rnn(x)                            \n        out = self.head(h.squeeze(0))\n        return out\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T16:10:21.041313Z","iopub.execute_input":"2025-04-27T16:10:21.042076Z","iopub.status.idle":"2025-04-27T16:10:44.094535Z","shell.execute_reply.started":"2025-04-27T16:10:21.042047Z","shell.execute_reply":"2025-04-27T16:10:44.093964Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Reading dataset with pandas:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"41f1fba96d0f49a1988ce3f1b66beafe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Reading dataset with pandas:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4f29e10a5333482895bb42b8143020ad"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Reading dataset with pandas:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f37cdb041e0c48b0a49bdace045f988e"}},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"model = CreditsRNN(features, embed_proj).to(device)\noptim = torch.optim.Adam(model.parameters(), lr=1e-3)\nbce   = nn.BCEWithLogitsLoss()\n\ndef train_epoch(model, gen, batches=1000):\n    model.train(); loss_sum = 0\n    for i, batch in enumerate(gen):\n        if i >= batches: break\n        optim.zero_grad()\n        logits = model(batch[\"features\"])\n        loss = bce(logits.squeeze(1).float(), batch[\"label\"].float())\n        loss.backward(); optim.step()\n        loss_sum += loss.item()\n    return loss_sum / (i+1)\n\n@torch.no_grad()\ndef eval_auc(model, gen, batches=300):\n    model.eval(); preds, labels = [], []\n    for i, batch in enumerate(gen):\n        if i >= batches: break\n        logits = model(batch[\"features\"]).squeeze(1).float().cpu().numpy()\n        preds.append(logits)\n        labels.append(batch[\"label\"].cpu().numpy())\n    return roc_auc_score(np.concatenate(labels), np.concatenate(preds))\n\nes = EarlyStopping(patience=3, mode=\"max\", verbose=True,\n                   save_path=\"/kaggle/working/best.pt\", metric_name=\"AUC\")\n\nfor epoch in range(10):\n    tr_loss = train_epoch(model, train_gen)\n    val_auc = eval_auc(model, val_gen)\n    print(f\"Epoch {epoch+1}: loss={tr_loss:.4f}, val_auc={val_auc:.5f}\")\n    es(val_auc, model)\n    if es.early_stop:\n        print(\"Early stopping.\")\n        break\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T16:12:50.959900Z","iopub.execute_input":"2025-04-27T16:12:50.960673Z","iopub.status.idle":"2025-04-27T16:14:12.552323Z","shell.execute_reply.started":"2025-04-27T16:12:50.960647Z","shell.execute_reply":"2025-04-27T16:14:12.551639Z"}},"outputs":[{"name":"stdout","text":"Epoch 1: loss=0.1398, val_auc=0.72438\nValidation AUC improved (-inf --> 0.724376).  Saving model...\nEpoch 2: loss=0.1280, val_auc=0.77492\nValidation AUC improved (0.724376 --> 0.774922).  Saving model...\nEpoch 3: loss=0.1308, val_auc=0.73599\nNo imporvement in validation AUC. Current: 0.735993. Current best: 0.774922\nEarlyStopping counter: 1 out of 3\nEpoch 4: loss=0.1360, val_auc=0.74812\nNo imporvement in validation AUC. Current: 0.748117. Current best: 0.774922\nEarlyStopping counter: 2 out of 3\nEpoch 5: loss=0.1402, val_auc=0.76572\nNo imporvement in validation AUC. Current: 0.765722. Current best: 0.774922\nEarlyStopping counter: 3 out of 3\nEarly stopping.\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"import torch, torch.nn as nn, torch.nn.functional as F\n\nclass AttnPool(nn.Module):\n    def __init__(self, d_model):\n        super().__init__()\n        self.q = nn.Linear(d_model, d_model, bias=False)\n        self.scale = d_model ** -0.5\n\n    def forward(self, h, mask=None):\n        # h: (B, T, H)\n        att = (self.q(h) * self.scale) @ h.transpose(1, 2)      \n        if mask is not None:\n            att.masked_fill_(mask[:, None, :]==0, -1e9)\n        w = F.softmax(att, dim=-1)                             \n        ctx = w @ h                                             \n        return ctx.mean(1)                                      \n\nclass CreditsRNN_Attn(nn.Module):\n    def __init__(self, features, emb_proj, hid=160, mlp=64,\n                 emb_dp=0.1, rnn_dp=0.2):\n        super().__init__()\n        self.embs = nn.ModuleList(\n            [nn.Embedding(n, d, padding_idx=0) for n, d in emb_proj.values()])\n        self.emb_dp = nn.Dropout(emb_dp)\n\n        d_in = sum(d for _, d in emb_proj.values())\n        self.norm_in = nn.LayerNorm(d_in)\n\n        self.gru = nn.GRU(d_in, hid, num_layers=2,\n                          batch_first=True, bidirectional=True,\n                          dropout=rnn_dp)\n\n        self.pool = AttnPool(hid*2)\n        self.head = nn.Sequential(\n            nn.Linear(hid*2, mlp),\n            nn.ReLU(),\n            nn.Dropout(0.25),\n            nn.Linear(mlp, 1)\n        )\n\n    def forward(self, feats):           \n        x = torch.cat([e(f) for e, f in zip(self.embs, feats)], dim=-1)\n        x = self.emb_dp(x)\n        x = self.norm_in(x)\n        h, _ = self.gru(x)\n        out = self.pool(h)\n        return self.head(out).squeeze(1)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T16:14:15.974877Z","iopub.execute_input":"2025-04-27T16:14:15.975622Z","iopub.status.idle":"2025-04-27T16:14:15.984872Z","shell.execute_reply.started":"2025-04-27T16:14:15.975575Z","shell.execute_reply":"2025-04-27T16:14:15.984239Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"def make_val_loader():\n    return batches_generator(\n        val_paths, batch_size=128, shuffle=False,\n        is_train=True, output_format=\"torch\", device=device\n    )\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T16:30:27.063986Z","iopub.execute_input":"2025-04-27T16:30:27.064732Z","iopub.status.idle":"2025-04-27T16:30:27.069265Z","shell.execute_reply.started":"2025-04-27T16:30:27.064698Z","shell.execute_reply":"2025-04-27T16:30:27.068464Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"from torch.amp import autocast, GradScaler\nimport random, numpy as np, torch.optim as optim\n\ndef set_seed(s):\n    random.seed(s); np.random.seed(s); torch.manual_seed(s)\n    torch.cuda.manual_seed_all(s)\n\ndef train_one_seed(seed):\n    set_seed(seed)\n    model = CreditsRNN_Attn(features, embed_proj).to(device)\n\n    opt = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-5)\n    scheduler = optim.lr_scheduler.ReduceLROnPlateau(opt, mode='max', factor=0.5,\n                                                     patience=1)\n    scaler = GradScaler('cuda')\n\n    best_auc, patience = 0., 0\n    for epoch in range(8):\n        model.train(); running = 0.\n        train_loader = batches_generator(   \n            train_paths, batch_size=128, shuffle=True,\n            is_train=True, output_format=\"torch\", device=device\n        )\n        for i, batch in enumerate(train_loader):\n            opt.zero_grad(set_to_none=True)\n            with autocast('cuda'): \n                logits = model(batch['features'])\n                loss = F.binary_cross_entropy_with_logits(\n                    logits.float(), batch['label'].float())\n            scaler.scale(loss).backward()\n            scaler.step(opt); scaler.update()\n            running += loss.item()\n\n        model.eval(); preds, y = [], []\n        val_loader = make_val_loader()\n        with torch.no_grad(), autocast('cuda'):\n            for batch in val_loader:\n                logits = model(batch['features']).float()\n                preds.append(logits.cpu())\n                y.append(batch['label'].cpu())\n\n        auc = roc_auc_score(torch.cat(y).numpy(),\n                            torch.cat(preds).numpy())\n        scheduler.step(auc)\n\n        if auc > best_auc + 1e-4:\n            best_auc, patience = auc, 0\n            torch.save(model.state_dict(), f\"/kaggle/working/best_{seed}.pt\")\n        else:\n            patience += 1\n            if patience == 3:\n                break\n        print(f\"seed {seed}  epoch {epoch+1}  loss {running/(i+1):.4f}  val AUC {auc:.5f}\")\n\n    return best_auc","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T16:30:53.970432Z","iopub.execute_input":"2025-04-27T16:30:53.970737Z","iopub.status.idle":"2025-04-27T16:30:53.980547Z","shell.execute_reply.started":"2025-04-27T16:30:53.970717Z","shell.execute_reply":"2025-04-27T16:30:53.979833Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"aucs = [train_one_seed(s) for s in (42, 777, 2025)]\nprint(\"single-seed AUCs:\", aucs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T16:30:56.329056Z","iopub.execute_input":"2025-04-27T16:30:56.329339Z","iopub.status.idle":"2025-04-27T18:41:21.783951Z","shell.execute_reply.started":"2025-04-27T16:30:56.329320Z","shell.execute_reply":"2025-04-27T18:41:21.782911Z"}},"outputs":[{"name":"stdout","text":"seed 42  epoch 1  loss 0.1389  val AUC 0.77216\nseed 42  epoch 2  loss 0.1357  val AUC 0.77856\nseed 42  epoch 3  loss 0.1349  val AUC 0.77783\nseed 42  epoch 4  loss 0.1347  val AUC 0.78048\nseed 42  epoch 5  loss 0.1345  val AUC 0.77956\nseed 42  epoch 6  loss 0.1339  val AUC 0.77673\nseed 777  epoch 1  loss 0.1390  val AUC 0.77052\nseed 777  epoch 2  loss 0.1359  val AUC 0.77715\nseed 777  epoch 3  loss 0.1349  val AUC 0.77909\nseed 777  epoch 4  loss 0.1344  val AUC 0.78012\nseed 777  epoch 6  loss 0.1342  val AUC 0.77903\nseed 777  epoch 7  loss 0.1335  val AUC 0.78197\nseed 777  epoch 8  loss 0.1330  val AUC 0.78223\nseed 2025  epoch 1  loss 0.1389  val AUC 0.77529\nseed 2025  epoch 2  loss 0.1354  val AUC 0.77500\nseed 2025  epoch 3  loss 0.1348  val AUC 0.77688\nseed 2025  epoch 4  loss 0.1345  val AUC 0.77901\nseed 2025  epoch 5  loss 0.1343  val AUC 0.77784\nseed 2025  epoch 6  loss 0.1343  val AUC 0.77729\nseed 2025  epoch 7  loss 0.1334  val AUC 0.78164\nseed 2025  epoch 8  loss 0.1331  val AUC 0.78198\nsingle-seed AUCs: [0.7804797043520586, 0.7822288807282166, 0.7819781484244162]\n","output_type":"stream"}],"execution_count":21}]}